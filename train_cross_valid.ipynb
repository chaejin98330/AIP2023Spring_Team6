{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "YWXJdNjmTYF-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import tqdm\n",
        "from tqdm.notebook import tqdm as notebooktqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import timm\n",
        "from timm.layers import BatchNormAct2d\n",
        "import os\n",
        "# from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# work place\n",
        "work_dir = './'\n",
        "os.chdir(work_dir)\n",
        "test_in_small = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "tgP-pcsnhB9M"
      },
      "outputs": [],
      "source": [
        "class YoutubeDataset(Dataset):\n",
        "    def __init__(self, data, doc2vec):\n",
        "        self.ids = list(data['video_id'])\n",
        "        self.titles = doc2vec # pretrained doc2vec features\n",
        "        self.data = data # video_id, metadata, views(y) from csv file\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.image_encoder = timm.create_model('efficientnet_b1_pruned', features_only =True, pretrained=True)\n",
        "        model = timm.create_model('efficientnet_b1_pruned', pretrained=True)\n",
        "        data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
        "        self.transform = timm.data.create_transform(**data_cfg)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # index order of video_id, meta, y are same\n",
        "        video_id = self.ids[idx]\n",
        "        \n",
        "        image = Image.open( work_dir+'medium_15287/{}.jpg'.format(video_id))\n",
        "        image = self.transform(image)\n",
        "        # image = torch.FloatTensor(np.array(image)).permute(2, 0, 1).unsqueeze(dim=0)\n",
        "        self.image_encoder.eval()\n",
        "        feature_map = self.image_encoder(torch.unsqueeze(image,0))[-1].squeeze() # (320,6,10)\n",
        "        \n",
        "        title = self.titles[video_id] # get video title\n",
        "        title = torch.FloatTensor(np.array(title, dtype=np.float16))\n",
        "        \n",
        "        meta = torch.FloatTensor(self.data[['period_day', 'subscriber_count']].to_numpy()[idx]) # get metadata\n",
        "        \n",
        "        y = np.log10(self.data['views'].to_numpy() + 1) # add 1 for zero views\n",
        "        y = np.expand_dims(y, axis=1) # add batch dimension\n",
        "        y = torch.FloatTensor(y[idx]) # get log10(views+1) by idx value\n",
        "        \n",
        "        return video_id, feature_map, title, meta, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "360Pm1IVTtmM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "335.8148713475796 497.7613157973895 1784323.5617822357 3833786.6144638904\n",
            "Train Dataset Size :  30\n",
            "Validation Dataset Size :  5\n",
            "Test Dataset Size :  5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>period_day</th>\n",
              "      <th>channel_title</th>\n",
              "      <th>subscriber_count</th>\n",
              "      <th>...</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>comment_count</th>\n",
              "      <th>description</th>\n",
              "      <th>desc_len</th>\n",
              "      <th>len_title</th>\n",
              "      <th>No_tags</th>\n",
              "      <th>video_error_or_removed</th>\n",
              "      <th>trending_date</th>\n",
              "      <th>comments_disabled</th>\n",
              "      <th>ratings_disabled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1636</td>\n",
              "      <td>uGOskK94nPU</td>\n",
              "      <td>14:00:35</td>\n",
              "      <td>2023-01-18</td>\n",
              "      <td>UCPqyMgj9n1GxSU-RyCjqLPA</td>\n",
              "      <td>Küçük, Orta ve Büyük Tabak Meydan Okumasi | Ye...</td>\n",
              "      <td>2005786</td>\n",
              "      <td>-0.457679</td>\n",
              "      <td>Multi DO Turkish</td>\n",
              "      <td>-0.405949</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>116.0</td>\n",
              "      <td>Bir sürü yiyecek elbette harikadır, ancak daha...</td>\n",
              "      <td>318.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4459</td>\n",
              "      <td>6Xu_RjV0Wjo</td>\n",
              "      <td>11:00:03</td>\n",
              "      <td>2023-05-05</td>\n",
              "      <td>UCsRNwIyd1WnjLR89mWtrC-A</td>\n",
              "      <td>일산 분위기 좋은 카페 찾으시나요? 여기어때요!</td>\n",
              "      <td>93</td>\n",
              "      <td>-0.672641</td>\n",
              "      <td>저두영 jodooyoung</td>\n",
              "      <td>-0.465411</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>일산 분위기 좋은 카페 좋아하세요? 저두영 \\n분위기가 좋은 일산 대형 베이커리 카...</td>\n",
              "      <td>360.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5168</td>\n",
              "      <td>MPU7iOsUJtI</td>\n",
              "      <td>08:30:04</td>\n",
              "      <td>2023-04-28</td>\n",
              "      <td>UC5GHkCa1PhGycqnEbp50KrQ</td>\n",
              "      <td>[와차밥] 차돌박이 된장국수 오이김치 고추김치 요리 먹방 Soybean Paste ...</td>\n",
              "      <td>87779</td>\n",
              "      <td>-0.658578</td>\n",
              "      <td>버들Buddle</td>\n",
              "      <td>-0.389517</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>74.0</td>\n",
              "      <td>🎵Music provided by 브금대통령\\n🎵Track : Candy - htt...</td>\n",
              "      <td>70.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14076</td>\n",
              "      <td>GZh1Qkr7uoA</td>\n",
              "      <td>08:12:19</td>\n",
              "      <td>2015-03-11</td>\n",
              "      <td>UCdwLMpZeFXN5ODyCO9warSw</td>\n",
              "      <td>BJ애봉이먹방 깐풍새우 &amp; 고추잡채 &amp; 불짜장 &amp; 볶음짬뽕</td>\n",
              "      <td>120826</td>\n",
              "      <td>5.308137</td>\n",
              "      <td>애봉이</td>\n",
              "      <td>-0.441815</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>38.0</td>\n",
              "      <td>(미국NPR 공영라디오방송취재중) USA NPR radio   좋아요 와 구독하기 ...</td>\n",
              "      <td>201.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13448</td>\n",
              "      <td>4omqsDYxQGw</td>\n",
              "      <td>01:00:00</td>\n",
              "      <td>2020-03-13</td>\n",
              "      <td>UC9d1Mz9bzCE-t_t0lPnrjPA</td>\n",
              "      <td>Fettuccine Alfredo Mukbang</td>\n",
              "      <td>233562</td>\n",
              "      <td>1.633685</td>\n",
              "      <td>BenDeen</td>\n",
              "      <td>-0.134156</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>580.0</td>\n",
              "      <td>Check out my Instagram: https://www.instagram....</td>\n",
              "      <td>219.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     video_id publish_time publish_date   \n",
              "0        1636  uGOskK94nPU     14:00:35   2023-01-18  \\\n",
              "1        4459  6Xu_RjV0Wjo     11:00:03   2023-05-05   \n",
              "2        5168  MPU7iOsUJtI     08:30:04   2023-04-28   \n",
              "3       14076  GZh1Qkr7uoA     08:12:19   2015-03-11   \n",
              "4       13448  4omqsDYxQGw     01:00:00   2020-03-13   \n",
              "\n",
              "                 channel_id   \n",
              "0  UCPqyMgj9n1GxSU-RyCjqLPA  \\\n",
              "1  UCsRNwIyd1WnjLR89mWtrC-A   \n",
              "2  UC5GHkCa1PhGycqnEbp50KrQ   \n",
              "3  UCdwLMpZeFXN5ODyCO9warSw   \n",
              "4  UC9d1Mz9bzCE-t_t0lPnrjPA   \n",
              "\n",
              "                                               title    views  period_day   \n",
              "0  Küçük, Orta ve Büyük Tabak Meydan Okumasi | Ye...  2005786   -0.457679  \\\n",
              "1                         일산 분위기 좋은 카페 찾으시나요? 여기어때요!       93   -0.672641   \n",
              "2  [와차밥] 차돌박이 된장국수 오이김치 고추김치 요리 먹방 Soybean Paste ...    87779   -0.658578   \n",
              "3                   BJ애봉이먹방 깐풍새우 & 고추잡채 & 불짜장 & 볶음짬뽕   120826    5.308137   \n",
              "4                         Fettuccine Alfredo Mukbang   233562    1.633685   \n",
              "\n",
              "      channel_title  subscriber_count  ... dislikes  comment_count   \n",
              "0  Multi DO Turkish         -0.405949  ...    False          116.0  \\\n",
              "1    저두영 jodooyoung         -0.465411  ...    False            0.0   \n",
              "2          버들Buddle         -0.389517  ...    False           74.0   \n",
              "3               애봉이         -0.441815  ...    False           38.0   \n",
              "4           BenDeen         -0.134156  ...    False          580.0   \n",
              "\n",
              "                                         description  desc_len  len_title   \n",
              "0  Bir sürü yiyecek elbette harikadır, ancak daha...     318.0       75.0  \\\n",
              "1  일산 분위기 좋은 카페 좋아하세요? 저두영 \\n분위기가 좋은 일산 대형 베이커리 카...     360.0       26.0   \n",
              "2  🎵Music provided by 브금대통령\\n🎵Track : Candy - htt...      70.0       98.0   \n",
              "3  (미국NPR 공영라디오방송취재중) USA NPR radio   좋아요 와 구독하기 ...     201.0       72.0   \n",
              "4  Check out my Instagram: https://www.instagram....     219.0       26.0   \n",
              "\n",
              "  No_tags  video_error_or_removed  trending_date  comments_disabled   \n",
              "0     0.0                   False            0.0              False  \\\n",
              "1     0.0                   False            0.0              False   \n",
              "2     0.0                   False            0.0              False   \n",
              "3     0.0                   False            0.0              False   \n",
              "4     0.0                   False            0.0              False   \n",
              "\n",
              "   ratings_disabled  \n",
              "0             False  \n",
              "1             False  \n",
              "2             False  \n",
              "3             False  \n",
              "4             False  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add nomarlizing\n",
        "data = pd.read_csv('./train.csv')\n",
        "mean_period = data['period_day'].mean()\n",
        "std_period = data['period_day'].std()\n",
        "mean_sub = data['subscriber_count'].mean()\n",
        "std_sub = data['subscriber_count'].std()\n",
        "print(mean_period, std_period, mean_sub, std_sub)\n",
        "\n",
        "data['period_day'] = (data['period_day'] - mean_period)/std_period\n",
        "data['subscriber_count'] = (data['subscriber_count']-mean_sub)/std_sub\n",
        "\n",
        "train_data, valid_data = train_test_split(data, test_size = 0.1, random_state = 55)\n",
        "test_data = pd.read_csv('./test.csv')\n",
        "\n",
        "\n",
        "if test_in_small:\n",
        "    train_data = train_data[:30]\n",
        "    valid_data = valid_data[:5]\n",
        "    test_data = test_data[:5]\n",
        "print('Train Dataset Size : ',len(train_data))\n",
        "print('Validation Dataset Size : ',len(valid_data))\n",
        "print('Test Dataset Size : ',len(test_data))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15287\n"
          ]
        }
      ],
      "source": [
        "# open doc2vec data and conver to dict\n",
        "with open('./title_doc2vec_10', 'rb') as f:\n",
        "    doc2vec = pickle.load(f)\n",
        "\n",
        "data_dict=dict()\n",
        "for row in doc2vec:\n",
        "    vid=row[0]\n",
        "    vec=row[1:]\n",
        "    data_dict[vid]=vec\n",
        "\n",
        "doc2vec = data_dict\n",
        "print(len(doc2vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RaVBtO6gmibN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#setting hyper parameters\n",
        "batch_size = 2\n",
        "epochs = 10\n",
        "lr = 0.0005\n",
        "save_every = 10\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "_d3vE8CgwOQK"
      },
      "outputs": [],
      "source": [
        "train_dataset = YoutubeDataset(train_data, doc2vec)\n",
        "valid_dataset = YoutubeDataset(valid_data, doc2vec)\n",
        "test_dataset = YoutubeDataset(test_data, doc2vec)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size = 1)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.feature_map_channel = 320\n",
        "        self.feature_map_h = 6\n",
        "        self.feature_map_w = 10\n",
        "\n",
        "        self.efficient_net_channel1 = 1280\n",
        "        self.efficient_net_channel2 = 1000\n",
        "\n",
        "        # image squeezing\n",
        "        self.img_squeeze_channel1 = self.efficient_net_channel2\n",
        "        self.img_squeeze_channel2 = 2000\n",
        "        self.img_squeeze_channel3 = 1000\n",
        "        self.img_squeeze_channel4 = 500\n",
        "        self.img_squeeze_channel_out = 100\n",
        "\n",
        "        # title squeezing\n",
        "        self.title_feature_channel = 10\n",
        "        self.title_squeeze_channel1 = 200\n",
        "        self.title_squeeze_channel2 = 100\n",
        "        self.title_squeeze_channel3 = 50\n",
        "        self.title_squeeze_channel_out = 10\n",
        "\n",
        "        # meta sqeezing\n",
        "        self.final_squeeze1 = 20\n",
        "        self.final_squeeze2 = 20\n",
        "        self.final_squeeze3 = 10\n",
        "        self.final_squeeze3 = 5\n",
        "        self.out_channel = 1\n",
        "        \n",
        "        # efficient net\n",
        "        self.effi1 = nn.Conv2d(self.feature_map_channel, self.efficient_net_channel1, kernel_size=(1,1), stride=(1,1), bias=False)\n",
        "        self.effi2 = nn.BatchNorm2d(self.efficient_net_channel1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.effi3 = nn.SiLU(inplace=True)\n",
        "        self.effi4 = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.effi5 = nn.Linear(self.efficient_net_channel1, self.efficient_net_channel2)\n",
        "        \n",
        "        # sqeeze img features\n",
        "        self.img_squeeze_fc1 = nn.Linear(self.img_squeeze_channel1, self.img_squeeze_channel2)\n",
        "        self.img_squeeze_fc2 = nn.Linear(self.img_squeeze_channel2, self.img_squeeze_channel3)\n",
        "        self.img_squeeze_fc3 = nn.Linear(self.img_squeeze_channel3, self.img_squeeze_channel4)\n",
        "        self.img_squeeze_fc_out = nn.Linear(self.img_squeeze_channel4, self.img_squeeze_channel_out)\n",
        " \n",
        "        # sqeeze img and title features\n",
        "        self.title_squeeze_fc1 = nn.Linear(self.img_squeeze_channel_out+self.title_feature_channel, self.title_squeeze_channel1)\n",
        "        self.title_squeeze_fc2 = nn.Linear(self.title_squeeze_channel1, self.title_squeeze_channel2)\n",
        "        self.title_squeeze_fc3 = nn.Linear(self.title_squeeze_channel2, self.title_squeeze_channel3)\n",
        "        self.title_squeeze_fc_out = nn.Linear(self.title_squeeze_channel3, self.title_squeeze_channel_out)\n",
        "\n",
        "        # sqeeze whole datas\n",
        "        self.final_concat_fc1 = nn.Linear(self.title_squeeze_channel_out+2, self.final_squeeze1)\n",
        "        self.final_concat_fc2 = nn.Linear(self.final_squeeze1, self.final_squeeze2)\n",
        "        self.final_concat_fc3 = nn.Linear(self.final_squeeze2, self.final_squeeze3)\n",
        "        self.final_concat_fc_out = nn.Linear(self.final_squeeze3, self.out_channel)\n",
        " \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.to(self.device)\n",
        "    \n",
        "    def forward(self, feature_map, title, meta):\n",
        "        feature_map = feature_map.to(self.device)\n",
        "        title = title.to(self.device)\n",
        "        meta = meta.to(self.device)\n",
        "\n",
        "        x = self.effi1(feature_map)\n",
        "        x = self.effi2(x)\n",
        "        x = self.effi3(x)\n",
        "        x = torch.squeeze(self.effi4(x), dim=(2,3))\n",
        "        x = self.effi5(x)\n",
        "\n",
        "        x = self.img_squeeze_fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.img_squeeze_fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.img_squeeze_fc3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.img_squeeze_fc_out(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        img_title_feature = torch.cat([x, title], dim=1)\n",
        "        img_title_feature = self.title_squeeze_fc1(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "        img_title_feature = self.title_squeeze_fc2(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "        img_title_feature = self.title_squeeze_fc3(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "        img_title_feature = self.title_squeeze_fc_out(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "\n",
        "        whole_feature = torch.cat([img_title_feature, meta], dim=1)\n",
        "        whole_feature = self.final_concat_fc1(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "        whole_feature = self.final_concat_fc2(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "        whole_feature = self.final_concat_fc3(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "        x = self.final_concat_fc_out(whole_feature)\n",
        "        return x\n",
        "\n",
        "    def train_(self, epochs, lr, train_loader, valid_loader, save_every):\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.valid_loss = []\n",
        "\n",
        "        best_mse = 1e100\n",
        "        best_epoch = 1\n",
        "\n",
        "        train_start = time.time()\n",
        "\n",
        "        print(\"Model will be trained on {}\\n\".format(self.device))\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            self.train()\n",
        "            print(\"[Epoch {:3d} / {}]\".format(epoch, epochs))\n",
        "\n",
        "            epoch_start = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            self.to(self.device)\n",
        "            #training\n",
        "            for batch_idx, batch_data in enumerate(notebooktqdm(train_loader, desc=\"Training\")):\n",
        "                batch_video_id, batch_image, batch_title, batch_meta, batch_target = batch_data\n",
        "                batch_target = batch_target.to(self.device)\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.forward(batch_image, batch_title, batch_meta)\n",
        "                loss = self.criterion(output, batch_target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_end = time.time()\n",
        "            m, s = divmod(epoch_end - epoch_start, 60)\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            \n",
        "            #validation\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                true_y, pred_y = self.predict(valid_loader)                \n",
        "                true_y = torch.FloatTensor(true_y).unsqueeze(dim=1)\n",
        "                pred_y = torch.FloatTensor(pred_y)\n",
        "                valid_loss = self.criterion(pred_y, true_y)\n",
        "                self.valid_loss.append(valid_loss.item())\n",
        "\n",
        "            print(\"Train MSE = {:.4f} | Valid MSE = {:.4f}\".format(epoch_loss, valid_loss))\n",
        "            print(f\"Train Time: {m:.0f}m {s:.0f}s\\n\")\n",
        "\n",
        "            valid_mse = valid_loss.item()\n",
        "            if best_mse > valid_mse:\n",
        "                print(\"=> Best Model Updated : Epoch = {}, Valid MSE = {:.4f}\\n\".format(epoch, valid_mse))\n",
        "                best_mse = valid_mse\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), \"./best_model/best_model.pt\")\n",
        "            else:\n",
        "                print()\n",
        "\n",
        "            # save model for every ? epoch\n",
        "            if (epoch % save_every) == 0:\n",
        "                torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "\n",
        "        m, s = divmod(time.time() - train_start, 60)\n",
        "        print(\"\\nTraining Finished...!!\")\n",
        "        print(\"\\nBest Valid MSE : %.2f at epoch %d\" % (best_mse, best_epoch))\n",
        "        print(f\"Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {self.device}!\")\n",
        "\n",
        "        torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "    \n",
        "    def restore(self):\n",
        "        with open(\"./best_model/best_model.pt\", \"rb\") as f:\n",
        "            state_dict = torch.load(f)\n",
        "        self.load_state_dict(state_dict)\n",
        "\n",
        "    def predict(self, dataloader):\n",
        "        self.to(device)\n",
        "        with torch.no_grad():\n",
        "            self.eval()\n",
        "            true_y = []\n",
        "            pred_y = []\n",
        "            for batch_video_id, batch_image, batch_title, batch_meta, batch_target in dataloader:\n",
        "                batch_image = batch_image.to(device)\n",
        "                batch_title = batch_title.to(device)\n",
        "                batch_meta = batch_meta.to(device)\n",
        "                pred = self.forward(batch_image, batch_title, batch_meta)\n",
        "                true_y.append(batch_target)\n",
        "                pred_y.append(pred)\n",
        "            true_y = torch.cat(true_y, dim=0).squeeze().cpu().numpy()\n",
        "            pred_y = torch.cat(pred_y, dim=0).cpu().numpy()\n",
        "        return true_y, pred_y #numpy array\n",
        "\n",
        "    def plot(self):\n",
        "        plt.plot(np.array(self.train_loss), \"b\")\n",
        "        plt.plot(np.array(self.valid_loss), \"g\")\n",
        "        plt.savefig(\"./graph.png\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Vn1sTA9K-DBX"
      },
      "outputs": [],
      "source": [
        "model = Model()\n",
        "# model.to(model.device)\n",
        "# model.train_(epochs, lr, train_loader, valid_loader, save_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split # 전체 데이터를 학습 데이터와 평가 데이터로 분할\n",
        "\n",
        "# ANN\n",
        "import torch\n",
        "from torch import nn, optim # torch 내의 세부적인 기능\n",
        "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용\n",
        "import torch.nn.functional as F # torch 내의 세부적인 기능\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Loss\n",
        "from sklearn.metrics import mean_squared_error # MSE(Mean Squared Error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluation(dataloader):\n",
        "    \n",
        "    predictions = torch.tensor([], dtype=torch.float) \n",
        "    actual = torch.tensor([], dtype=torch.float) \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        model.eval() \n",
        "        for batch_video_id, batch_image, batch_title, batch_meta, batch_target in dataloader:\n",
        "            outputs = model(batch_image, batch_title, batch_meta) \n",
        "\n",
        "            predictions = torch.cat((predictions, outputs), 0) \n",
        "            actual = torch.cat((actual, batch_target), 0) \n",
        "    \n",
        "    predictions = predictions.numpy() \n",
        "    actual = actual.numpy() \n",
        "    rmse = np.sqrt(mean_squared_error(predictions, actual)) \n",
        "    model.train()\n",
        "    return rmse  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr:  0.005 weight_decay:  0\n",
            "k-fold 0  Train Loss: 4.8045, Validation Loss: 5.1635\n",
            "k-fold 1  Train Loss: 4.4984, Validation Loss: 4.2283\n",
            "k-fold 2  Train Loss: 4.8648, Validation Loss: 4.7801\n",
            "Validation Score: 4.7240, ± 0.3839\n",
            "lr:  0.005 weight_decay:  0.001\n",
            "k-fold 0  Train Loss: 4.5952, Validation Loss: 4.6387\n",
            "k-fold 1  Train Loss: 4.3918, Validation Loss: 4.5437\n",
            "k-fold 2  Train Loss: 4.7952, Validation Loss: 4.6100\n",
            "Validation Score: 4.5975, ± 0.0398\n",
            "lr:  0.005 weight_decay:  1e-05\n",
            "k-fold 0  Train Loss: 4.1595, Validation Loss: 4.9001\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "\n",
        "learning_rates = [ 0.005 ,0.001, 0.0001 ]\n",
        "weight_decays = [0, 1e-3, 1e-5]\n",
        "epoches = 3\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-7)\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for _weight_decay in weight_decays:\n",
        "        optimizer.param_groups[0]['lr'] = learning_rate\n",
        "        optimizer.param_groups[0]['weight_decay'] = _weight_decay\n",
        "        print(\"lr: \", optimizer.param_groups[0]['lr'], \"weight_decay: \", optimizer.param_groups[0]['weight_decay'])\n",
        "        validation_loss = []\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)): \n",
        "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx) \n",
        "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx) \n",
        "            \n",
        "            trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=train_subsampler) \n",
        "            valloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=val_subsampler)\n",
        "            \n",
        "            # 모델\n",
        "            model = Model()\n",
        "            \n",
        "            for epoch in range(epoches): \n",
        "\n",
        "                for batch_video_id, batch_image, batch_title, batch_meta, batch_target in trainloader: \n",
        "\n",
        "                    optimizer.zero_grad() \n",
        "\n",
        "                    outputs = model(batch_image, batch_title, batch_meta) \n",
        "                    loss = criterion(outputs, batch_target) \n",
        "                    loss.backward() \n",
        "                    optimizer.step() \n",
        "\n",
        "            train_rmse = evaluation(trainloader) \n",
        "            val_rmse = evaluation(valloader)\n",
        "            print(\"k-fold\", fold,\" Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse)) \n",
        "            validation_loss.append(val_rmse)\n",
        "\n",
        "        validation_loss = np.array(validation_loss)\n",
        "        mean = np.mean(validation_loss)\n",
        "        std = np.std(validation_loss)\n",
        "        print(\"Validation Score: %.4f, ± %.4f\" %(mean, std))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
