{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "9epXksKByLI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b933d9e-7dac-4f88-cbfc-9015f415e895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/인지프"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZuCasd0-ruO",
        "outputId": "f255a8f7-d1db-4f82-cad4-53cc1da78123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/인지프\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRdpc7aMxXWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19cbfd3-d0c5-40b5-de44-7b964692ba0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference\n"
          ]
        }
      ],
      "source": [
        "# import package\n",
        "\n",
        "# model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "\n",
        "# dataset and transformation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "\n",
        "# display images\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# utils\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Using {device} for inference')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "\n",
        "import csv\n",
        "import shutil\n",
        "\n",
        "train_list = []\n",
        "test_list = []\n",
        "\n",
        "with open('train.csv', 'r', encoding='utf-8') as f:\n",
        "  rdr = csv.reader(f)\n",
        "  for line in rdr:\n",
        "      train_list.append(line[1])\n",
        "\n",
        "with open('test.csv', 'r', encoding='utf-8') as f:\n",
        "  rdr = csv.reader(f)\n",
        "  for line in rdr:\n",
        "      test_list.append(line[1])\n",
        "\n",
        "# full_data_path = './data/'\n",
        "\n",
        "train_list = train_list[1:]\n",
        "test_list = test_list[1:]\n",
        "\n",
        "print(f'csv len: {len(test_list) + len(train_list)}')\n",
        "# print(f'full data len: {len(os.listdir(\"./data\"))}')\n",
        "\n",
        "# for test in tqdm(test_list):\n",
        "#   if os.path.exists('./data/' + test + '.jpg'):  \n",
        "#     img_path = glob('./data/' + test + '.jpg')[0]\n",
        "#     shutil.copyfile(img_path, './test/' + test + '.jpg')\n",
        "  \n",
        "#   else:\n",
        "#     print(test)\n",
        "\n",
        "# for train in tqdm(train_list):\n",
        "#   if os.path.exists('./data/' + train + '.jpg'):  \n",
        "#     img_path = glob('./data/' + train + '.jpg')[0]\n",
        "#     shutil.copyfile(img_path, './train/' + train + '.jpg')\n",
        "#   else:\n",
        "#     print(train)\n",
        "\n",
        "print(f'test len: {len(os.listdir(\"./test\"))}')\n",
        "print(f'train len: {len(os.listdir(\"./train\"))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGLTLgTq8_Ki",
        "outputId": "c44d9153-9ac6-4599-a945-57684b689338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv len: 15287\n",
            "test len: 1529\n",
            "train len: 13758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch\n",
        "\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')"
      ],
      "metadata": {
        "id": "XWT6QQ1cyY2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1def69-eff9-4182-9951-8da4b84cb9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class SampleDataset(Dataset):\n",
        "    def __init__(self, phase='test'):\n",
        "        # self.path = './sample_data'\n",
        "        self.phase = phase\n",
        "        \n",
        "        self.img_list = glob(self.phase + '/*')\n",
        "\n",
        "        self.transform = transform=transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Pad(padding=(0, 140), padding_mode='reflect'),\n",
        "                               transforms.Resize((224, 224))\n",
        "                         ])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_list[idx]\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        img = self.transform(img)\n",
        "\n",
        "        vid = img_path.split('/')[-1][:-4]\n",
        "        # print(vid)\n",
        "\n",
        "        return img, vid"
      ],
      "metadata": {
        "id": "KBm_91Y_dWL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sample input data.\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_dataset = SampleDataset(phase='test')\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_dataset = SampleDataset(phase='train')\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "EqZCd5hpywDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "save_data = {}\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, vid in tqdm(test_dataloader):\n",
        "    features = efficientnet.extract_features(img)\n",
        "    # print(features.shape)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "      if b < len(vid):\n",
        "        save_data[vid[b]] = features[b]\n",
        "\n",
        "print(f'test len: {len(test_list)}')\n",
        "print(f'data len: {len(save_data)}')\n",
        "\n",
        "with open('test.txt', 'wb') as f:\n",
        "  pickle.dump(save_data, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "dQhTl9yoI4eI",
        "outputId": "376803fe-9157-4a93-fc73-510544b431c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-380dbd1c435f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# num_img = img[0].numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_data = {}\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, vid in tqdm(train_dataloader):\n",
        "    \n",
        "    features = efficientnet.extract_features(img)\n",
        "    # print(features.shape)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "      if b < len(vid):\n",
        "        save_data[vid[b]] = features[b]\n",
        "\n",
        "print(f'train len: {len(train_list)}')\n",
        "print(f'data len: {len(save_data)}')\n",
        "\n",
        "with open('train.pickle', 'wb') as f:\n",
        "  pickle.dump(save_data, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "fUsP3Ih2RPBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 로더 안쓰는 버전"
      ],
      "metadata": {
        "id": "Cgjc5WvUOTg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # without dataloader ver\n",
        "\n",
        "# from PIL import Image\n",
        "# import pickle\n",
        "\n",
        "# save_data = {}\n",
        "\n",
        "# transform = transform=transforms.Compose([\n",
        "#                                transforms.ToTensor(),\n",
        "#                                transforms.Pad(padding=(0, 140), padding_mode='reflect'),\n",
        "#                                transforms.Resize((224, 224))\n",
        "#                       ])\n",
        "\n",
        "# for vid in tqdm(test_list):\n",
        "#   img_path = './test/' + vid + '.jpg'\n",
        "\n",
        "#   img = Image.open(img_path)\n",
        "#   img = transform(img).unsqueeze(0)\n",
        "\n",
        "#   # print(img.shape)\n",
        "\n",
        "#   features = efficientnet.extract_features(img)\n",
        "#   # print(features.shape)\n",
        "\n",
        "#   save_data[vid] = features\n",
        "\n",
        "# with open('test.pickle', 'wb') as f:\n",
        "#   pickle.dump(save_data, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "lrhRukTVI4Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96CIwfune6Ku"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}