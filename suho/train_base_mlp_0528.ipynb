{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YWXJdNjmTYF-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import tqdm\n",
        "from tqdm.notebook import tqdm as notebooktqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import timm\n",
        "from timm.layers import BatchNormAct2d\n",
        "import os\n",
        "# from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# work place\n",
        "work_dir = './'\n",
        "os.chdir(work_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tgP-pcsnhB9M"
      },
      "outputs": [],
      "source": [
        "class YoutubeDataset(Dataset):\n",
        "    def __init__(self, data, doc2vec):\n",
        "        self.ids = list(data['video_id'])\n",
        "        self.titles = doc2vec # pretrained doc2vec features\n",
        "        self.data = data # video_id, metadata, views(y) from csv file\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.image_encoder = timm.create_model('efficientnet_b1_pruned', features_only =True, pretrained=True)\n",
        "        model = timm.create_model('efficientnet_b1_pruned', pretrained=True)\n",
        "        data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
        "        self.transform = timm.data.create_transform(**data_cfg)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # index order of video_id, meta, y are same\n",
        "        video_id = self.ids[idx]\n",
        "        \n",
        "        image = Image.open( work_dir+'medium_15287/{}.jpg'.format(video_id))\n",
        "        image = self.transform(image)\n",
        "        # image = torch.FloatTensor(np.array(image)).permute(2, 0, 1).unsqueeze(dim=0)\n",
        "        self.image_encoder.eval()\n",
        "        feature_map = self.image_encoder(torch.unsqueeze(image,0))[-1].squeeze() # (320,6,10)\n",
        "        \n",
        "        title = self.titles[video_id] # get video title\n",
        "        title = torch.FloatTensor(np.array(title, dtype=np.float16))\n",
        "        \n",
        "        meta = torch.FloatTensor(self.data[['period_day', 'subscriber_count']].to_numpy()[idx]) # get metadata\n",
        "        \n",
        "        y = np.log10(self.data['views'].to_numpy() + 1) # add 1 for zero views\n",
        "        y = np.expand_dims(y, axis=1) # add batch dimension\n",
        "        y = torch.FloatTensor(y[idx]) # get log10(views+1) by idx value\n",
        "        \n",
        "        return video_id, feature_map, title, meta, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "360Pm1IVTtmM"
      },
      "outputs": [],
      "source": [
        "# # add nomarlizing\n",
        "# data = pd.read_csv('./train.csv')\n",
        "# mean_period = data['period_day'].mean()\n",
        "# std_period = data['period_day'].std()\n",
        "# mean_sub = data['subscriber_count'].mean()\n",
        "# std_sub = data['subscriber_count'].std()\n",
        "# print(mean_period, std_period, mean_sub, std_sub)\n",
        "\n",
        "# data['period_day'] = (data['period_day'] - mean_period)/std_period\n",
        "# data['subscriber_count'] = (data['subscriber_count']-mean_sub)/std_sub\n",
        "\n",
        "# train_data, valid_data = train_test_split(data, test_size = 0.1, random_state = 55)\n",
        "# test_data = pd.read_csv('./test.csv')\n",
        "# train_data = train_data[:1000]\n",
        "# valid_data = valid_data[:100]\n",
        "# test_data = test_data[:100]\n",
        "# print('Train Dataset Size : ',len(train_data))\n",
        "# print('Validation Dataset Size : ',len(valid_data))\n",
        "# print('Test Dataset Size : ',len(test_data))\n",
        "\n",
        "# data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset Size :  12382\n",
            "Validation Dataset Size :  1376\n",
            "Test Dataset Size :  1529\n"
          ]
        }
      ],
      "source": [
        "# upload\n",
        "train_data = pd.read_csv('./train.csv')\n",
        "test_data = pd.read_csv('./test.csv')\n",
        "\n",
        "mean_period = train_data['period_day'].mean()\n",
        "std_period = train_data['period_day'].std()\n",
        "mean_subscriber = train_data['subscriber_count'].mean()\n",
        "std_subscriber = train_data['subscriber_count'].std()\n",
        "\n",
        "# train data nomarlization\n",
        "train_data['period_day'] = (train_data['period_day'] - mean_period) / std_period\n",
        "train_data['subscriber_count'] = (train_data['subscriber_count'] - mean_subscriber) / std_subscriber\n",
        "\n",
        "# test data nomarlization\n",
        "test_data['period_day'] = (test_data['period_day'] - mean_period) / std_period\n",
        "test_data['subscriber_count'] = (test_data['subscriber_count'] - mean_subscriber) / std_subscriber\n",
        "\n",
        "# split train -> train : valid = 9 : 1\n",
        "train_data, valid_data = train_test_split(train_data, test_size = 0.1, random_state = 55)\n",
        "print('Train Dataset Size : ',len(train_data))\n",
        "print('Validation Dataset Size : ',len(valid_data))\n",
        "print('Test Dataset Size : ',len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15287\n"
          ]
        }
      ],
      "source": [
        "# open doc2vec data and conver to dict\n",
        "with open('./title_doc2vec_10', 'rb') as f:\n",
        "    doc2vec = pickle.load(f)\n",
        "\n",
        "data_dict=dict()\n",
        "for row in doc2vec:\n",
        "    vid=row[0]\n",
        "    vec=row[1:]\n",
        "    data_dict[vid]=vec\n",
        "\n",
        "doc2vec = data_dict\n",
        "print(len(doc2vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RaVBtO6gmibN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#setting hyper parameters\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "lr = 0.0005\n",
        "save_every = 20\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_d3vE8CgwOQK"
      },
      "outputs": [],
      "source": [
        "train_dataset = YoutubeDataset(train_data, doc2vec)\n",
        "valid_dataset = YoutubeDataset(valid_data, doc2vec)\n",
        "test_dataset = YoutubeDataset(test_data, doc2vec)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size = 1)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.feature_map_channel = 320\n",
        "        self.feature_map_h = 6\n",
        "        self.feature_map_w = 10\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.efficient_net_channel1 = 1280\n",
        "        self.efficient_net_channel2 = 1000\n",
        "\n",
        "        # image squeezing\n",
        "        self.img_squeeze_channel1 = self.efficient_net_channel2\n",
        "        self.img_squeeze_channel2 = 2000\n",
        "        self.img_squeeze_channel3 = 1000\n",
        "        self.img_squeeze_channel4 = 500\n",
        "        self.img_squeeze_channel_out = 100\n",
        "\n",
        "        # title squeezing\n",
        "        self.title_feature_channel = 10\n",
        "        self.title_squeeze_channel1 = 200\n",
        "        self.title_squeeze_channel2 = 100\n",
        "        self.title_squeeze_channel3 = 50\n",
        "        self.title_squeeze_channel_out = 10\n",
        "\n",
        "        # meta sqeezing\n",
        "        self.final_squeeze1 = 20\n",
        "        self.final_squeeze2 = 20\n",
        "        self.final_squeeze3 = 10\n",
        "        self.final_squeeze3 = 5\n",
        "        self.out_channel = 1\n",
        "        \n",
        "        # efficient net\n",
        "        self.effi1 = nn.Conv2d(self.feature_map_channel, self.efficient_net_channel1, kernel_size=(1,1), stride=(1,1), bias=False)\n",
        "        self.effi2 = nn.BatchNorm2d(self.efficient_net_channel1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.effi3 = nn.SiLU(inplace=True)\n",
        "        self.effi4 = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.effi5 = nn.Linear(self.efficient_net_channel1, self.efficient_net_channel2)\n",
        "        \n",
        "        # sqeeze img features\n",
        "        self.img_squeeze_fc1 = nn.Linear(self.img_squeeze_channel1, self.img_squeeze_channel2)\n",
        "        self.img_squeeze_fc2 = nn.Linear(self.img_squeeze_channel2, self.img_squeeze_channel3)\n",
        "        self.img_squeeze_fc3 = nn.Linear(self.img_squeeze_channel3, self.img_squeeze_channel4)\n",
        "        self.img_squeeze_fc_out = nn.Linear(self.img_squeeze_channel4, self.img_squeeze_channel_out)\n",
        " \n",
        "        # sqeeze img and title features\n",
        "        self.title_squeeze_fc1 = nn.Linear(self.img_squeeze_channel_out+self.title_feature_channel, self.title_squeeze_channel1)\n",
        "        self.title_squeeze_fc2 = nn.Linear(self.title_squeeze_channel1, self.title_squeeze_channel2)\n",
        "        self.title_squeeze_fc3 = nn.Linear(self.title_squeeze_channel2, self.title_squeeze_channel3)\n",
        "        self.title_squeeze_fc_out = nn.Linear(self.title_squeeze_channel3, self.title_squeeze_channel_out)\n",
        "\n",
        "        # sqeeze whole datas\n",
        "        self.final_concat_fc1 = nn.Linear(self.title_squeeze_channel_out+2, self.final_squeeze1)\n",
        "        self.final_concat_fc2 = nn.Linear(self.final_squeeze1, self.final_squeeze2)\n",
        "        self.final_concat_fc3 = nn.Linear(self.final_squeeze2, self.final_squeeze3)\n",
        "        self.final_concat_fc_out = nn.Linear(self.final_squeeze3, self.out_channel)\n",
        " \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.to(self.device)\n",
        "    \n",
        "    def forward(self, feature_map, title, meta):\n",
        "        feature_map = feature_map.to(self.device)\n",
        "        title = title.to(self.device)\n",
        "        meta = meta.to(self.device)\n",
        "\n",
        "        x = self.effi1(feature_map)\n",
        "        x = self.effi2(x)\n",
        "        x = self.effi3(x)\n",
        "        x = torch.squeeze(self.effi4(x), dim=(2,3))\n",
        "        x = self.effi5(x)\n",
        "\n",
        "        \n",
        "\n",
        "        x = self.img_squeeze_fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.img_squeeze_fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.img_squeeze_fc3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.img_squeeze_fc_out(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "\n",
        "\n",
        "        img_title_feature = torch.cat([x, title], dim=1)\n",
        "        img_title_feature = self.title_squeeze_fc1(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "\n",
        "        img_title_feature = self.title_squeeze_fc2(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "\n",
        "        img_title_feature = self.title_squeeze_fc3(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "\n",
        "        img_title_feature = self.title_squeeze_fc_out(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "\n",
        "\n",
        "\n",
        "        whole_feature = torch.cat([img_title_feature, meta], dim=1)\n",
        "        whole_feature = self.final_concat_fc1(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "\n",
        "        whole_feature = self.final_concat_fc2(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "\n",
        "        whole_feature = self.final_concat_fc3(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "\n",
        "        x = self.final_concat_fc_out(whole_feature)\n",
        "        return x\n",
        "\n",
        "    def train_(self, epochs, lr, train_loader, valid_loader, save_every):\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.valid_loss = []\n",
        "\n",
        "        best_mse = 1e100\n",
        "        best_epoch = 1\n",
        "\n",
        "        train_start = time.time()\n",
        "\n",
        "        print(\"Model will be trained on {}\\n\".format(self.device))\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            self.train()\n",
        "            print(\"[Epoch {:3d} / {}]\".format(epoch, epochs))\n",
        "\n",
        "            epoch_start = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            self.to(self.device)\n",
        "            #training\n",
        "            for batch_idx, batch_data in enumerate(notebooktqdm(train_loader, desc=\"Training\")):\n",
        "                batch_video_id, batch_image, batch_title, batch_meta, batch_target = batch_data\n",
        "                batch_target = batch_target.to(self.device)\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.forward(batch_image, batch_title, batch_meta)\n",
        "                loss = self.criterion(output, batch_target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_end = time.time()\n",
        "            m, s = divmod(epoch_end - epoch_start, 60)\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            \n",
        "            #validation\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                true_y, pred_y = self.predict(valid_loader)                \n",
        "                true_y = torch.FloatTensor(true_y)\n",
        "                pred_y = torch.FloatTensor(pred_y)\n",
        "                valid_loss = self.criterion(pred_y, true_y)\n",
        "                self.valid_loss.append(valid_loss.item())\n",
        "\n",
        "            print(\"Train MSE = {:.4f} | Valid MSE = {:.4f}\".format(epoch_loss, valid_loss))\n",
        "            print(f\"Train Time: {m:.0f}m {s:.0f}s\\n\")\n",
        "\n",
        "            valid_mse = valid_loss.item()\n",
        "            if best_mse > valid_mse:\n",
        "                print(\"=> Best Model Updated : Epoch = {}, Valid MSE = {:.4f}\\n\".format(epoch, valid_mse))\n",
        "                best_mse = valid_mse\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), \"./model/best_model_epoch{}.pt\".format(epoch))\n",
        "            else:\n",
        "                print()\n",
        "\n",
        "            # save model for every ? epoch\n",
        "            if (epoch % save_every) == 0:\n",
        "                torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "\n",
        "        m, s = divmod(time.time() - train_start, 60)\n",
        "        print(\"\\nTraining Finished...!!\")\n",
        "        print(\"\\nBest Valid MSE : %.2f at epoch %d\" % (best_mse, best_epoch))\n",
        "        print(f\"Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {self.device}!\")\n",
        "\n",
        "        torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "    \n",
        "    def restore(self):\n",
        "        with open(\"./best_model/best_model.pt\", \"rb\") as f:\n",
        "            state_dict = torch.load(f)\n",
        "        self.load_state_dict(state_dict)\n",
        "\n",
        "    def predict(self, dataloader):\n",
        "        self.to(device)\n",
        "        with torch.no_grad():\n",
        "            self.eval()\n",
        "            true_y = []\n",
        "            pred_y = []\n",
        "            for batch_video_id, batch_image, batch_title, batch_meta, batch_target in dataloader:\n",
        "                batch_image = batch_image.to(device)\n",
        "                batch_title = batch_title.to(device)\n",
        "                batch_meta = batch_meta.to(device)\n",
        "                pred = self.forward(batch_image, batch_title, batch_meta)\n",
        "                true_y.append(batch_target.numpy())\n",
        "                pred_y.append(pred.cpu().numpy())\n",
        "            pred_y = np.concatenate(pred_y, axis=0)\n",
        "            true_y = np.concatenate(true_y, axis=0)\n",
        "        return true_y, pred_y #numpy array\n",
        "\n",
        "    def plot(self):\n",
        "        plt.plot(np.array(self.train_loss), \"b\")\n",
        "        plt.plot(np.array(self.valid_loss), \"g\")\n",
        "        plt.savefig(\"./graph.png\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Vn1sTA9K-DBX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model will be trained on cuda:0\n",
            "\n",
            "[Epoch   1 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dbea130e6884663b38bfb59a6bfad01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 13.8434 | Valid MSE = 8.8133\n",
            "Train Time: 17m 4s\n",
            "\n",
            "=> Best Model Updated : Epoch = 1, Valid MSE = 8.8133\n",
            "\n",
            "[Epoch   2 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33d111202f734d8db9053b630b1f23ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 8.1965 | Valid MSE = 9.7246\n",
            "Train Time: 16m 57s\n",
            "\n",
            "\n",
            "[Epoch   3 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc9f4e4aa45c40b388709a949e265d93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Model()\n",
        "model.to(model.device)\n",
        "model.train_(epochs, lr, train_loader, valid_loader, save_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_plot(train_loss, valid_loss, x_axis):\n",
        "    plt.plot([i for i in range(x_axis[0], x_axis[1])], np.array(train_loss), \"b\")\n",
        "    plt.plot([i for i in range(x_axis[0], x_axis[1])], np.array(valid_loss), \"g\")\n",
        "    plt.xlim(x_axis)\n",
        "    plt.savefig(\"./loss_graph.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss_plot(model.train_loss[10:], model.valid_loss[10:], x_axis=[10, len(model.valid_loss)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1529, 1]) torch.Size([1529, 1])\n",
            "Test MSE :  1.318480134010315\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "model = Model()\n",
        "model.restore() # load best model during training\n",
        "pred_y, true_y = model.predict(test_loader)\n",
        "\n",
        "true_y = torch.FloatTensor(true_y)\n",
        "pred_y = torch.FloatTensor(pred_y)\n",
        "\n",
        "# pred_y = torch.unsqueeze(pred_y, dim=1)\n",
        "\n",
        "print(pred_y.shape, true_y.shape)\n",
        "test_mse = model.criterion(pred_y, true_y)\n",
        "print('Test MSE : ',test_mse.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Base_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Base_Model, self).__init__()\n",
        "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.feature_map_channel = 320\n",
        "        self.feature_map_h = 6\n",
        "        self.feature_map_w = 10\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.efficient_net_channel1 = 1280\n",
        "        self.efficient_net_channel2 = 1000\n",
        "\n",
        "        self.fc1 = nn.Linear(20492, 400) # using image\n",
        "        self.fc2 = nn.Linear(400, 20) # using image\n",
        "        self.fc3 = nn.Linear(20, 1) # using image\n",
        " \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.to(self.device)\n",
        "    \n",
        "    def forward(self, feature_map, title, meta):\n",
        "        feature_map = feature_map.to(self.device)\n",
        "        title = title.to(self.device)\n",
        "        meta = meta.to(self.device)\n",
        "\n",
        "        feature_map = torch.flatten(feature_map, start_dim=1)\n",
        "        x = torch.cat([feature_map, title, meta], dim=1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def train_(self, epochs, lr, train_loader, valid_loader, save_every):\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.valid_loss = []\n",
        "\n",
        "        best_mse = 1e100\n",
        "        best_epoch = 1\n",
        "\n",
        "        train_start = time.time()\n",
        "\n",
        "        print(\"Model will be trained on {}\\n\".format(self.device))\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            self.train()\n",
        "            print(\"[Epoch {:3d} / {}]\".format(epoch, epochs))\n",
        "\n",
        "            epoch_start = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            self.to(self.device)\n",
        "            #training\n",
        "            for batch_idx, batch_data in enumerate(notebooktqdm(train_loader, desc=\"Training\")):\n",
        "                batch_video_id, batch_image, batch_title, batch_meta, batch_target = batch_data\n",
        "                batch_target = batch_target.to(self.device)\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.forward(batch_image, batch_title, batch_meta)\n",
        "                loss = self.criterion(output, batch_target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_end = time.time()\n",
        "            m, s = divmod(epoch_end - epoch_start, 60)\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            \n",
        "            #validation\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                true_y, pred_y = self.predict(valid_loader)                \n",
        "                true_y = torch.FloatTensor(true_y)\n",
        "                pred_y = torch.FloatTensor(pred_y)\n",
        "                valid_loss = self.criterion(pred_y, true_y)\n",
        "                self.valid_loss.append(valid_loss.item())\n",
        "\n",
        "            print(\"Train MSE = {:.4f} | Valid MSE = {:.4f}\".format(epoch_loss, valid_loss))\n",
        "            print(f\"Train Time: {m:.0f}m {s:.0f}s\\n\")\n",
        "\n",
        "            valid_mse = valid_loss.item()\n",
        "            if best_mse > valid_mse:\n",
        "                print(\"=> Best Model Updated : Epoch = {}, Valid MSE = {:.4f}\\n\".format(epoch, valid_mse))\n",
        "                best_mse = valid_mse\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), \"./model/best_model_epoch{}.pt\".format(epoch))\n",
        "            else:\n",
        "                print()\n",
        "\n",
        "            # save model for every ? epoch\n",
        "            if (epoch % save_every) == 0:\n",
        "                torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "\n",
        "        m, s = divmod(time.time() - train_start, 60)\n",
        "        print(\"\\nTraining Finished...!!\")\n",
        "        print(\"\\nBest Valid MSE : %.2f at epoch %d\" % (best_mse, best_epoch))\n",
        "        print(f\"Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {self.device}!\")\n",
        "\n",
        "        torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "    \n",
        "    def restore(self):\n",
        "        with open(\"./best_model/best_model.pt\", \"rb\") as f:\n",
        "            state_dict = torch.load(f)\n",
        "        self.load_state_dict(state_dict)\n",
        "\n",
        "    def predict(self, dataloader):\n",
        "        self.to(device)\n",
        "        with torch.no_grad():\n",
        "            self.eval()\n",
        "            true_y = []\n",
        "            pred_y = []\n",
        "            for batch_video_id, batch_image, batch_title, batch_meta, batch_target in dataloader:\n",
        "                batch_image = batch_image.to(device)\n",
        "                batch_title = batch_title.to(device)\n",
        "                batch_meta = batch_meta.to(device)\n",
        "                pred = self.forward(batch_image, batch_title, batch_meta)\n",
        "                true_y.append(batch_target.numpy())\n",
        "                pred_y.append(pred.cpu().numpy())\n",
        "            pred_y = np.concatenate(pred_y, axis=0)\n",
        "            true_y = np.concatenate(true_y, axis=0)\n",
        "        return true_y, pred_y #numpy array\n",
        "\n",
        "    def plot(self):\n",
        "        plt.plot(np.array(self.train_loss), \"b\")\n",
        "        plt.plot(np.array(self.valid_loss), \"g\")\n",
        "        plt.savefig(\"./graph.png\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6295411 8205241\n"
          ]
        }
      ],
      "source": [
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "\n",
        "model_our = Model()\n",
        "model_base = Base_Model()\n",
        "print(get_n_params(model_our), get_n_params(model_base))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model will be trained on cuda:0\n",
            "\n",
            "[Epoch   1 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e1d4e0f4d6a4ee5a4dbed7403f5d6c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 2.5501 | Valid MSE = 1.8797\n",
            "Train Time: 17m 14s\n",
            "\n",
            "=> Best Model Updated : Epoch = 1, Valid MSE = 1.8797\n",
            "\n",
            "[Epoch   2 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcfc36030843456fbd859ef4d912ea15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 1.3222 | Valid MSE = 1.9643\n",
            "Train Time: 16m 55s\n",
            "\n",
            "\n",
            "[Epoch   3 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9931ed400497484ea4e1b76d32cdf399",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 0.8490 | Valid MSE = 1.9564\n",
            "Train Time: 16m 58s\n",
            "\n",
            "\n",
            "[Epoch   4 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f546205088f54147ab3ac434ef080ed8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 0.5664 | Valid MSE = 1.9608\n",
            "Train Time: 16m 54s\n",
            "\n",
            "\n",
            "[Epoch   5 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d22af932b11941759cd6e4e7da11e903",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 0.3958 | Valid MSE = 1.9783\n",
            "Train Time: 16m 57s\n",
            "\n",
            "\n",
            "[Epoch   6 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f47ad1ee4f714242b36b4c303ee159c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 0.2847 | Valid MSE = 1.9350\n",
            "Train Time: 16m 47s\n",
            "\n",
            "\n",
            "[Epoch   7 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "896634408abf41c9847c74f4e575718c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 0.2124 | Valid MSE = 1.8757\n",
            "Train Time: 16m 52s\n",
            "\n",
            "=> Best Model Updated : Epoch = 7, Valid MSE = 1.8757\n",
            "\n",
            "[Epoch   8 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "104ccaa603b644729006ef071c65e573",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 0.1641 | Valid MSE = 1.8714\n",
            "Train Time: 16m 53s\n",
            "\n",
            "=> Best Model Updated : Epoch = 8, Valid MSE = 1.8714\n",
            "\n",
            "[Epoch   9 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca0d1a14111543b48d4846da8fe97d5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE = 0.1211 | Valid MSE = 1.8397\n",
            "Train Time: 16m 52s\n",
            "\n",
            "=> Best Model Updated : Epoch = 9, Valid MSE = 1.8397\n",
            "\n",
            "[Epoch  10 / 200]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9697d7a791b455c9518279433b1821b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/194 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_base.to(model_base.device)\n",
        "model_base.train_(epochs, lr, train_loader, valid_loader, save_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test\n",
        "model = Model()\n",
        "model.restore() # load best model during training\n",
        "pred_y, true_y = model.predict(test_loader)\n",
        "\n",
        "true_y = torch.FloatTensor(true_y)\n",
        "pred_y = torch.FloatTensor(pred_y)\n",
        "\n",
        "# pred_y = torch.unsqueeze(pred_y, dim=1)\n",
        "\n",
        "print(pred_y.shape, true_y.shape)\n",
        "test_mse = model.criterion(pred_y, true_y)\n",
        "print('Test MSE : ',test_mse.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
