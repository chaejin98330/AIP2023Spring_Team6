{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "YWXJdNjmTYF-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import tqdm\n",
        "from tqdm.notebook import tqdm as notebooktqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import timm\n",
        "from timm.layers import BatchNormAct2d\n",
        "import os\n",
        "# from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# work place\n",
        "work_dir = './'\n",
        "os.chdir(work_dir)\n",
        "test_in_small = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "tgP-pcsnhB9M"
      },
      "outputs": [],
      "source": [
        "class YoutubeDataset(Dataset):\n",
        "    def __init__(self, data, doc2vec):\n",
        "        self.ids = list(data['video_id'])\n",
        "        self.titles = doc2vec # pretrained doc2vec features\n",
        "        self.data = data # video_id, metadata, views(y) from csv file\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.image_encoder = timm.create_model('efficientnet_b1_pruned', features_only =True, pretrained=True)\n",
        "        model = timm.create_model('efficientnet_b1_pruned', pretrained=True)\n",
        "        data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
        "        self.transform = timm.data.create_transform(**data_cfg)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # index order of video_id, meta, y are same\n",
        "        video_id = self.ids[idx]\n",
        "        \n",
        "        image = Image.open( work_dir+'medium_15287/{}.jpg'.format(video_id))\n",
        "        image = self.transform(image)\n",
        "        # image = torch.FloatTensor(np.array(image)).permute(2, 0, 1).unsqueeze(dim=0)\n",
        "        self.image_encoder.eval()\n",
        "        feature_map = self.image_encoder(torch.unsqueeze(image,0))[-1].squeeze() # (320,6,10)\n",
        "        \n",
        "        title = self.titles[video_id] # get video title\n",
        "        title = torch.FloatTensor(np.array(title, dtype=np.float16))\n",
        "        \n",
        "        meta = torch.FloatTensor(self.data[['period_day', 'subscriber_count']].to_numpy()[idx]) # get metadata\n",
        "        \n",
        "        y = np.log10(self.data['views'].to_numpy() + 1) # add 1 for zero views\n",
        "        y = np.expand_dims(y, axis=1) # add batch dimension\n",
        "        y = torch.FloatTensor(y[idx]) # get log10(views+1) by idx value\n",
        "        \n",
        "        return video_id, feature_map, title, meta, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "360Pm1IVTtmM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "335.8148713475796 497.7613157973895 1784323.5617822357 3833786.6144638904\n",
            "Train Dataset Size :  30\n",
            "Validation Dataset Size :  5\n",
            "Test Dataset Size :  5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>period_day</th>\n",
              "      <th>channel_title</th>\n",
              "      <th>subscriber_count</th>\n",
              "      <th>...</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>comment_count</th>\n",
              "      <th>description</th>\n",
              "      <th>desc_len</th>\n",
              "      <th>len_title</th>\n",
              "      <th>No_tags</th>\n",
              "      <th>video_error_or_removed</th>\n",
              "      <th>trending_date</th>\n",
              "      <th>comments_disabled</th>\n",
              "      <th>ratings_disabled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1636</td>\n",
              "      <td>uGOskK94nPU</td>\n",
              "      <td>14:00:35</td>\n",
              "      <td>2023-01-18</td>\n",
              "      <td>UCPqyMgj9n1GxSU-RyCjqLPA</td>\n",
              "      <td>K√º√ß√ºk, Orta ve B√ºy√ºk Tabak Meydan Okumasi | Ye...</td>\n",
              "      <td>2005786</td>\n",
              "      <td>-0.457679</td>\n",
              "      <td>Multi DO Turkish</td>\n",
              "      <td>-0.405949</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>116.0</td>\n",
              "      <td>Bir s√ºr√º yiyecek elbette harikadƒ±r, ancak daha...</td>\n",
              "      <td>318.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4459</td>\n",
              "      <td>6Xu_RjV0Wjo</td>\n",
              "      <td>11:00:03</td>\n",
              "      <td>2023-05-05</td>\n",
              "      <td>UCsRNwIyd1WnjLR89mWtrC-A</td>\n",
              "      <td>ÏùºÏÇ∞ Î∂ÑÏúÑÍ∏∞ Ï¢ãÏùÄ Ïπ¥Ìéò Ï∞æÏúºÏãúÎÇòÏöî? Ïó¨Í∏∞Ïñ¥ÎïåÏöî!</td>\n",
              "      <td>93</td>\n",
              "      <td>-0.672641</td>\n",
              "      <td>Ï†ÄÎëêÏòÅ jodooyoung</td>\n",
              "      <td>-0.465411</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ÏùºÏÇ∞ Î∂ÑÏúÑÍ∏∞ Ï¢ãÏùÄ Ïπ¥Ìéò Ï¢ãÏïÑÌïòÏÑ∏Ïöî? Ï†ÄÎëêÏòÅ \\nÎ∂ÑÏúÑÍ∏∞Í∞Ä Ï¢ãÏùÄ ÏùºÏÇ∞ ÎåÄÌòï Î≤†Ïù¥Ïª§Î¶¨ Ïπ¥...</td>\n",
              "      <td>360.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5168</td>\n",
              "      <td>MPU7iOsUJtI</td>\n",
              "      <td>08:30:04</td>\n",
              "      <td>2023-04-28</td>\n",
              "      <td>UC5GHkCa1PhGycqnEbp50KrQ</td>\n",
              "      <td>[ÏôÄÏ∞®Î∞•] Ï∞®ÎèåÎ∞ïÏù¥ ÎêúÏû•Íµ≠Ïàò Ïò§Ïù¥ÍπÄÏπò Í≥†Ï∂îÍπÄÏπò ÏöîÎ¶¨ Î®πÎ∞© Soybean Paste ...</td>\n",
              "      <td>87779</td>\n",
              "      <td>-0.658578</td>\n",
              "      <td>Î≤ÑÎì§Buddle</td>\n",
              "      <td>-0.389517</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>74.0</td>\n",
              "      <td>üéµMusic provided by Î∏åÍ∏àÎåÄÌÜµÎ†π\\nüéµTrack : Candy - htt...</td>\n",
              "      <td>70.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14076</td>\n",
              "      <td>GZh1Qkr7uoA</td>\n",
              "      <td>08:12:19</td>\n",
              "      <td>2015-03-11</td>\n",
              "      <td>UCdwLMpZeFXN5ODyCO9warSw</td>\n",
              "      <td>BJÏï†Î¥âÏù¥Î®πÎ∞© ÍπêÌíçÏÉàÏö∞ &amp; Í≥†Ï∂îÏû°Ï±Ñ &amp; Î∂àÏßúÏû• &amp; Î≥∂ÏùåÏß¨ÎΩï</td>\n",
              "      <td>120826</td>\n",
              "      <td>5.308137</td>\n",
              "      <td>Ïï†Î¥âÏù¥</td>\n",
              "      <td>-0.441815</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>38.0</td>\n",
              "      <td>(ÎØ∏Íµ≠NPR Í≥µÏòÅÎùºÎîîÏò§Î∞©ÏÜ°Ï∑®Ïû¨Ï§ë) USA NPR radio   Ï¢ãÏïÑÏöî ÏôÄ Íµ¨ÎèÖÌïòÍ∏∞ ...</td>\n",
              "      <td>201.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13448</td>\n",
              "      <td>4omqsDYxQGw</td>\n",
              "      <td>01:00:00</td>\n",
              "      <td>2020-03-13</td>\n",
              "      <td>UC9d1Mz9bzCE-t_t0lPnrjPA</td>\n",
              "      <td>Fettuccine Alfredo Mukbang</td>\n",
              "      <td>233562</td>\n",
              "      <td>1.633685</td>\n",
              "      <td>BenDeen</td>\n",
              "      <td>-0.134156</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>580.0</td>\n",
              "      <td>Check out my Instagram: https://www.instagram....</td>\n",
              "      <td>219.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     video_id publish_time publish_date   \n",
              "0        1636  uGOskK94nPU     14:00:35   2023-01-18  \\\n",
              "1        4459  6Xu_RjV0Wjo     11:00:03   2023-05-05   \n",
              "2        5168  MPU7iOsUJtI     08:30:04   2023-04-28   \n",
              "3       14076  GZh1Qkr7uoA     08:12:19   2015-03-11   \n",
              "4       13448  4omqsDYxQGw     01:00:00   2020-03-13   \n",
              "\n",
              "                 channel_id   \n",
              "0  UCPqyMgj9n1GxSU-RyCjqLPA  \\\n",
              "1  UCsRNwIyd1WnjLR89mWtrC-A   \n",
              "2  UC5GHkCa1PhGycqnEbp50KrQ   \n",
              "3  UCdwLMpZeFXN5ODyCO9warSw   \n",
              "4  UC9d1Mz9bzCE-t_t0lPnrjPA   \n",
              "\n",
              "                                               title    views  period_day   \n",
              "0  K√º√ß√ºk, Orta ve B√ºy√ºk Tabak Meydan Okumasi | Ye...  2005786   -0.457679  \\\n",
              "1                         ÏùºÏÇ∞ Î∂ÑÏúÑÍ∏∞ Ï¢ãÏùÄ Ïπ¥Ìéò Ï∞æÏúºÏãúÎÇòÏöî? Ïó¨Í∏∞Ïñ¥ÎïåÏöî!       93   -0.672641   \n",
              "2  [ÏôÄÏ∞®Î∞•] Ï∞®ÎèåÎ∞ïÏù¥ ÎêúÏû•Íµ≠Ïàò Ïò§Ïù¥ÍπÄÏπò Í≥†Ï∂îÍπÄÏπò ÏöîÎ¶¨ Î®πÎ∞© Soybean Paste ...    87779   -0.658578   \n",
              "3                   BJÏï†Î¥âÏù¥Î®πÎ∞© ÍπêÌíçÏÉàÏö∞ & Í≥†Ï∂îÏû°Ï±Ñ & Î∂àÏßúÏû• & Î≥∂ÏùåÏß¨ÎΩï   120826    5.308137   \n",
              "4                         Fettuccine Alfredo Mukbang   233562    1.633685   \n",
              "\n",
              "      channel_title  subscriber_count  ... dislikes  comment_count   \n",
              "0  Multi DO Turkish         -0.405949  ...    False          116.0  \\\n",
              "1    Ï†ÄÎëêÏòÅ jodooyoung         -0.465411  ...    False            0.0   \n",
              "2          Î≤ÑÎì§Buddle         -0.389517  ...    False           74.0   \n",
              "3               Ïï†Î¥âÏù¥         -0.441815  ...    False           38.0   \n",
              "4           BenDeen         -0.134156  ...    False          580.0   \n",
              "\n",
              "                                         description  desc_len  len_title   \n",
              "0  Bir s√ºr√º yiyecek elbette harikadƒ±r, ancak daha...     318.0       75.0  \\\n",
              "1  ÏùºÏÇ∞ Î∂ÑÏúÑÍ∏∞ Ï¢ãÏùÄ Ïπ¥Ìéò Ï¢ãÏïÑÌïòÏÑ∏Ïöî? Ï†ÄÎëêÏòÅ \\nÎ∂ÑÏúÑÍ∏∞Í∞Ä Ï¢ãÏùÄ ÏùºÏÇ∞ ÎåÄÌòï Î≤†Ïù¥Ïª§Î¶¨ Ïπ¥...     360.0       26.0   \n",
              "2  üéµMusic provided by Î∏åÍ∏àÎåÄÌÜµÎ†π\\nüéµTrack : Candy - htt...      70.0       98.0   \n",
              "3  (ÎØ∏Íµ≠NPR Í≥µÏòÅÎùºÎîîÏò§Î∞©ÏÜ°Ï∑®Ïû¨Ï§ë) USA NPR radio   Ï¢ãÏïÑÏöî ÏôÄ Íµ¨ÎèÖÌïòÍ∏∞ ...     201.0       72.0   \n",
              "4  Check out my Instagram: https://www.instagram....     219.0       26.0   \n",
              "\n",
              "  No_tags  video_error_or_removed  trending_date  comments_disabled   \n",
              "0     0.0                   False            0.0              False  \\\n",
              "1     0.0                   False            0.0              False   \n",
              "2     0.0                   False            0.0              False   \n",
              "3     0.0                   False            0.0              False   \n",
              "4     0.0                   False            0.0              False   \n",
              "\n",
              "   ratings_disabled  \n",
              "0             False  \n",
              "1             False  \n",
              "2             False  \n",
              "3             False  \n",
              "4             False  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add nomarlizing\n",
        "data = pd.read_csv('./train.csv')\n",
        "mean_period = data['period_day'].mean()\n",
        "std_period = data['period_day'].std()\n",
        "mean_sub = data['subscriber_count'].mean()\n",
        "std_sub = data['subscriber_count'].std()\n",
        "print(mean_period, std_period, mean_sub, std_sub)\n",
        "\n",
        "data['period_day'] = (data['period_day'] - mean_period)/std_period\n",
        "data['subscriber_count'] = (data['subscriber_count']-mean_sub)/std_sub\n",
        "\n",
        "train_data, valid_data = train_test_split(data, test_size = 0.1, random_state = 55)\n",
        "test_data = pd.read_csv('./test.csv')\n",
        "\n",
        "\n",
        "if test_in_small:\n",
        "    train_data = train_data[:30]\n",
        "    valid_data = valid_data[:5]\n",
        "    test_data = test_data[:5]\n",
        "print('Train Dataset Size : ',len(train_data))\n",
        "print('Validation Dataset Size : ',len(valid_data))\n",
        "print('Test Dataset Size : ',len(test_data))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15287\n"
          ]
        }
      ],
      "source": [
        "# open doc2vec data and conver to dict\n",
        "with open('./title_doc2vec_10', 'rb') as f:\n",
        "    doc2vec = pickle.load(f)\n",
        "\n",
        "data_dict=dict()\n",
        "for row in doc2vec:\n",
        "    vid=row[0]\n",
        "    vec=row[1:]\n",
        "    data_dict[vid]=vec\n",
        "\n",
        "doc2vec = data_dict\n",
        "print(len(doc2vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RaVBtO6gmibN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#setting hyper parameters\n",
        "batch_size = 2\n",
        "epochs = 10\n",
        "lr = 0.0005\n",
        "save_every = 10\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "_d3vE8CgwOQK"
      },
      "outputs": [],
      "source": [
        "train_dataset = YoutubeDataset(train_data, doc2vec)\n",
        "valid_dataset = YoutubeDataset(valid_data, doc2vec)\n",
        "test_dataset = YoutubeDataset(test_data, doc2vec)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size = 1)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.feature_map_channel = 320\n",
        "        self.feature_map_h = 6\n",
        "        self.feature_map_w = 10\n",
        "\n",
        "        self.efficient_net_channel1 = 1280\n",
        "        self.efficient_net_channel2 = 1000\n",
        "\n",
        "        # image squeezing\n",
        "        self.img_squeeze_channel1 = self.efficient_net_channel2\n",
        "        self.img_squeeze_channel2 = 2000\n",
        "        self.img_squeeze_channel3 = 1000\n",
        "        self.img_squeeze_channel4 = 500\n",
        "        self.img_squeeze_channel_out = 100\n",
        "\n",
        "        # title squeezing\n",
        "        self.title_feature_channel = 10\n",
        "        self.title_squeeze_channel1 = 200\n",
        "        self.title_squeeze_channel2 = 100\n",
        "        self.title_squeeze_channel3 = 50\n",
        "        self.title_squeeze_channel_out = 10\n",
        "\n",
        "        # meta sqeezing\n",
        "        self.final_squeeze1 = 20\n",
        "        self.final_squeeze2 = 20\n",
        "        self.final_squeeze3 = 10\n",
        "        self.final_squeeze3 = 5\n",
        "        self.out_channel = 1\n",
        "        \n",
        "        # efficient net\n",
        "        self.effi1 = nn.Conv2d(self.feature_map_channel, self.efficient_net_channel1, kernel_size=(1,1), stride=(1,1), bias=False)\n",
        "        self.effi2 = nn.BatchNorm2d(self.efficient_net_channel1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.effi3 = nn.SiLU(inplace=True)\n",
        "        self.effi4 = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.effi5 = nn.Linear(self.efficient_net_channel1, self.efficient_net_channel2)\n",
        "        \n",
        "        # sqeeze img features\n",
        "        self.img_squeeze_fc1 = nn.Linear(self.img_squeeze_channel1, self.img_squeeze_channel2)\n",
        "        self.img_squeeze_fc2 = nn.Linear(self.img_squeeze_channel2, self.img_squeeze_channel3)\n",
        "        self.img_squeeze_fc3 = nn.Linear(self.img_squeeze_channel3, self.img_squeeze_channel4)\n",
        "        self.img_squeeze_fc_out = nn.Linear(self.img_squeeze_channel4, self.img_squeeze_channel_out)\n",
        " \n",
        "        # sqeeze img and title features\n",
        "        self.title_squeeze_fc1 = nn.Linear(self.img_squeeze_channel_out+self.title_feature_channel, self.title_squeeze_channel1)\n",
        "        self.title_squeeze_fc2 = nn.Linear(self.title_squeeze_channel1, self.title_squeeze_channel2)\n",
        "        self.title_squeeze_fc3 = nn.Linear(self.title_squeeze_channel2, self.title_squeeze_channel3)\n",
        "        self.title_squeeze_fc_out = nn.Linear(self.title_squeeze_channel3, self.title_squeeze_channel_out)\n",
        "\n",
        "        # sqeeze whole datas\n",
        "        self.final_concat_fc1 = nn.Linear(self.title_squeeze_channel_out+2, self.final_squeeze1)\n",
        "        self.final_concat_fc2 = nn.Linear(self.final_squeeze1, self.final_squeeze2)\n",
        "        self.final_concat_fc3 = nn.Linear(self.final_squeeze2, self.final_squeeze3)\n",
        "        self.final_concat_fc_out = nn.Linear(self.final_squeeze3, self.out_channel)\n",
        " \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.to(self.device)\n",
        "    \n",
        "    def forward(self, feature_map, title, meta):\n",
        "        feature_map = feature_map.to(self.device)\n",
        "        title = title.to(self.device)\n",
        "        meta = meta.to(self.device)\n",
        "\n",
        "        x = self.effi1(feature_map)\n",
        "        x = self.effi2(x)\n",
        "        x = self.effi3(x)\n",
        "        x = torch.squeeze(self.effi4(x), dim=(2,3))\n",
        "        x = self.effi5(x)\n",
        "\n",
        "        x = self.img_squeeze_fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.img_squeeze_fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.img_squeeze_fc3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.img_squeeze_fc_out(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        img_title_feature = torch.cat([x, title], dim=1)\n",
        "        img_title_feature = self.title_squeeze_fc1(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "        img_title_feature = self.title_squeeze_fc2(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "        img_title_feature = self.title_squeeze_fc3(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "        img_title_feature = self.title_squeeze_fc_out(img_title_feature)\n",
        "        img_title_feature = self.dropout(img_title_feature)\n",
        "        img_title_feature = self.relu(img_title_feature)\n",
        "\n",
        "        whole_feature = torch.cat([img_title_feature, meta], dim=1)\n",
        "        whole_feature = self.final_concat_fc1(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "        whole_feature = self.final_concat_fc2(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "        whole_feature = self.final_concat_fc3(whole_feature)\n",
        "        whole_feature = self.dropout(whole_feature)\n",
        "        whole_feature = self.relu(whole_feature)\n",
        "        x = self.final_concat_fc_out(whole_feature)\n",
        "        return x\n",
        "\n",
        "    def train_(self, epochs, lr, train_loader, valid_loader, save_every):\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.valid_loss = []\n",
        "\n",
        "        best_mse = 1e100\n",
        "        best_epoch = 1\n",
        "\n",
        "        train_start = time.time()\n",
        "\n",
        "        print(\"Model will be trained on {}\\n\".format(self.device))\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            self.train()\n",
        "            print(\"[Epoch {:3d} / {}]\".format(epoch, epochs))\n",
        "\n",
        "            epoch_start = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            self.to(self.device)\n",
        "            #training\n",
        "            for batch_idx, batch_data in enumerate(notebooktqdm(train_loader, desc=\"Training\")):\n",
        "                batch_video_id, batch_image, batch_title, batch_meta, batch_target = batch_data\n",
        "                batch_target = batch_target.to(self.device)\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.forward(batch_image, batch_title, batch_meta)\n",
        "                loss = self.criterion(output, batch_target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_end = time.time()\n",
        "            m, s = divmod(epoch_end - epoch_start, 60)\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            \n",
        "            #validation\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                true_y, pred_y = self.predict(valid_loader)                \n",
        "                true_y = torch.FloatTensor(true_y).unsqueeze(dim=1)\n",
        "                pred_y = torch.FloatTensor(pred_y)\n",
        "                valid_loss = self.criterion(pred_y, true_y)\n",
        "                self.valid_loss.append(valid_loss.item())\n",
        "\n",
        "            print(\"Train MSE = {:.4f} | Valid MSE = {:.4f}\".format(epoch_loss, valid_loss))\n",
        "            print(f\"Train Time: {m:.0f}m {s:.0f}s\\n\")\n",
        "\n",
        "            valid_mse = valid_loss.item()\n",
        "            if best_mse > valid_mse:\n",
        "                print(\"=> Best Model Updated : Epoch = {}, Valid MSE = {:.4f}\\n\".format(epoch, valid_mse))\n",
        "                best_mse = valid_mse\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), \"./best_model/best_model.pt\")\n",
        "            else:\n",
        "                print()\n",
        "\n",
        "            # save model for every ? epoch\n",
        "            if (epoch % save_every) == 0:\n",
        "                torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "\n",
        "        m, s = divmod(time.time() - train_start, 60)\n",
        "        print(\"\\nTraining Finished...!!\")\n",
        "        print(\"\\nBest Valid MSE : %.2f at epoch %d\" % (best_mse, best_epoch))\n",
        "        print(f\"Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {self.device}!\")\n",
        "\n",
        "        torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "    \n",
        "    def restore(self):\n",
        "        with open(\"./best_model/best_model.pt\", \"rb\") as f:\n",
        "            state_dict = torch.load(f)\n",
        "        self.load_state_dict(state_dict)\n",
        "\n",
        "    def predict(self, dataloader):\n",
        "        self.to(device)\n",
        "        with torch.no_grad():\n",
        "            self.eval()\n",
        "            true_y = []\n",
        "            pred_y = []\n",
        "            for batch_video_id, batch_image, batch_title, batch_meta, batch_target in dataloader:\n",
        "                batch_image = batch_image.to(device)\n",
        "                batch_title = batch_title.to(device)\n",
        "                batch_meta = batch_meta.to(device)\n",
        "                pred = self.forward(batch_image, batch_title, batch_meta)\n",
        "                true_y.append(batch_target)\n",
        "                pred_y.append(pred)\n",
        "            true_y = torch.cat(true_y, dim=0).squeeze().cpu().numpy()\n",
        "            pred_y = torch.cat(pred_y, dim=0).cpu().numpy()\n",
        "        return true_y, pred_y #numpy array\n",
        "\n",
        "    def plot(self):\n",
        "        plt.plot(np.array(self.train_loss), \"b\")\n",
        "        plt.plot(np.array(self.valid_loss), \"g\")\n",
        "        plt.savefig(\"./graph.png\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Vn1sTA9K-DBX"
      },
      "outputs": [],
      "source": [
        "model = Model()\n",
        "# model.to(model.device)\n",
        "# model.train_(epochs, lr, train_loader, valid_loader, save_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î•º ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏôÄ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞Î°ú Î∂ÑÌï†\n",
        "\n",
        "# ANN\n",
        "import torch\n",
        "from torch import nn, optim # torch ÎÇ¥Ïùò ÏÑ∏Î∂ÄÏ†ÅÏù∏ Í∏∞Îä•\n",
        "from torch.utils.data import DataLoader, Dataset # Îç∞Ïù¥ÌÑ∞Î•º Î™®Îç∏Ïóê ÏÇ¨Ïö©\n",
        "import torch.nn.functional as F # torch ÎÇ¥Ïùò ÏÑ∏Î∂ÄÏ†ÅÏù∏ Í∏∞Îä•\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Loss\n",
        "from sklearn.metrics import mean_squared_error # MSE(Mean Squared Error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluation(dataloader):\n",
        "    \n",
        "    predictions = torch.tensor([], dtype=torch.float) \n",
        "    actual = torch.tensor([], dtype=torch.float) \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        model.eval() \n",
        "        for batch_video_id, batch_image, batch_title, batch_meta, batch_target in dataloader:\n",
        "            outputs = model(batch_image, batch_title, batch_meta) \n",
        "\n",
        "            predictions = torch.cat((predictions, outputs), 0) \n",
        "            actual = torch.cat((actual, batch_target), 0) \n",
        "    \n",
        "    predictions = predictions.numpy() \n",
        "    actual = actual.numpy() \n",
        "    rmse = np.sqrt(mean_squared_error(predictions, actual)) \n",
        "    model.train()\n",
        "    return rmse  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr:  0.005 weight_decay:  0\n",
            "k-fold 0  Train Loss: 4.8045, Validation Loss: 5.1635\n",
            "k-fold 1  Train Loss: 4.4984, Validation Loss: 4.2283\n",
            "k-fold 2  Train Loss: 4.8648, Validation Loss: 4.7801\n",
            "Validation Score: 4.7240, ¬± 0.3839\n",
            "lr:  0.005 weight_decay:  0.001\n",
            "k-fold 0  Train Loss: 4.5952, Validation Loss: 4.6387\n",
            "k-fold 1  Train Loss: 4.3918, Validation Loss: 4.5437\n",
            "k-fold 2  Train Loss: 4.7952, Validation Loss: 4.6100\n",
            "Validation Score: 4.5975, ¬± 0.0398\n",
            "lr:  0.005 weight_decay:  1e-05\n",
            "k-fold 0  Train Loss: 4.1595, Validation Loss: 4.9001\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "\n",
        "learning_rates = [ 0.005 ,0.001, 0.0001 ]\n",
        "weight_decays = [0, 1e-3, 1e-5]\n",
        "epoches = 3\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-7)\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for _weight_decay in weight_decays:\n",
        "        optimizer.param_groups[0]['lr'] = learning_rate\n",
        "        optimizer.param_groups[0]['weight_decay'] = _weight_decay\n",
        "        print(\"lr: \", optimizer.param_groups[0]['lr'], \"weight_decay: \", optimizer.param_groups[0]['weight_decay'])\n",
        "        validation_loss = []\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)): \n",
        "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx) \n",
        "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx) \n",
        "            \n",
        "            trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=train_subsampler) \n",
        "            valloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=val_subsampler)\n",
        "            \n",
        "            # Î™®Îç∏\n",
        "            model = Model()\n",
        "            \n",
        "            for epoch in range(epoches): \n",
        "\n",
        "                for batch_video_id, batch_image, batch_title, batch_meta, batch_target in trainloader: \n",
        "\n",
        "                    optimizer.zero_grad() \n",
        "\n",
        "                    outputs = model(batch_image, batch_title, batch_meta) \n",
        "                    loss = criterion(outputs, batch_target) \n",
        "                    loss.backward() \n",
        "                    optimizer.step() \n",
        "\n",
        "            train_rmse = evaluation(trainloader) \n",
        "            val_rmse = evaluation(valloader)\n",
        "            print(\"k-fold\", fold,\" Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse)) \n",
        "            validation_loss.append(val_rmse)\n",
        "\n",
        "        validation_loss = np.array(validation_loss)\n",
        "        mean = np.mean(validation_loss)\n",
        "        std = np.std(validation_loss)\n",
        "        print(\"Validation Score: %.4f, ¬± %.4f\" %(mean, std))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
