{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWXJdNjmTYF-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import files\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from PIL import Image\n",
        "import time\n",
        "import tqdm\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class YoutubeDataset(Dataset):\n",
        "    def __init__(self, data, image_data):\n",
        "        images = []\n",
        "        for id in data['video_id']:\n",
        "            images.append(image_data[id].flatten())\n",
        "        images = np.array(images) # (N, HWC)\n",
        "        titles = None # here\n",
        "        metadata = data[['period_day', 'subscriber_count']].to_numpy() # (N, 2)\n",
        "        self.x = np.concatenate((images, titles, metadata), axis=1) # (N, HWC + 3)\n",
        "        self.y = np.log10(data['view_count'].to_numpy())\n",
        "\n",
        "        print(self.x.shape) # Testing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.FloatTensor(self.x[idx])\n",
        "        y = torch.FloatTensor(self.y[idx])\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "tgP-pcsnhB9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        # here\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # here\n",
        "        return x\n",
        "\n",
        "    def train_(self, epochs, lr, train_loader, valid_loader, save_every):\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.valid_loss = []\n",
        "\n",
        "        best_mse = -1\n",
        "        best_epoch = -1\n",
        "\n",
        "        train_start = time.time()\n",
        "\n",
        "        print(\"Model will be trained on {}\\n\".format(self.device))\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            self.train()\n",
        "            print(\"[Epoch {:3d} / {}]\".format(epoch, epochs))\n",
        "\n",
        "            epoch_start = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            \n",
        "            #training\n",
        "            for batch_idx, (data, target) in enumerate(tqdm.tqdm(train_loader, desc=\"Training\")):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.forward(data)\n",
        "\n",
        "                loss = self.criterion(output, target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_end = time.time()\n",
        "            m, s = divmod(epoch_end - epoch_start, 60)\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            \n",
        "            #validation\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                true_y, pred_y = self.predict(valid_loader)\n",
        "                valid_loss = self.criterion(pred_y, true_y)\n",
        "                self.valid_loss.append(valid_loss.item())\n",
        "\n",
        "            print(\"Train MSE = {:.4f} | Valid MSE = {:.4f}\".format(epoch_loss, valid_loss))\n",
        "            print(f\"Train Time: {m:.0f}m {s:.0f}s\\n\")\n",
        "\n",
        "            valid_mse = valid_loss.item()\n",
        "            if best_mse < valid_mse:\n",
        "                print(\"=> Best Model Updated : Epoch = {}, Valid MSE = {:.4f}\\n\".format(epoch, valid_mse))\n",
        "                best_mse = valid_mse\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), \"./best_model/best_model.pt\")\n",
        "            else:\n",
        "                print()\n",
        "\n",
        "            if (epoch % save_every) == 0:\n",
        "                torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "\n",
        "        m, s = divmod(time.time() - train_start, 60)\n",
        "        print(\"\\nTraining Finished...!!\")\n",
        "        print(\"\\nBest Valid MSE : %.2f at epoch %d\" % (best_mse, best_epoch))\n",
        "        print(f\"Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {self.device}!\")\n",
        "\n",
        "        torch.save(self.state_dict(),\"./model/epoch{}_train{:.4f}_valid{:.4f}.pt\".format(epoch, epoch_loss, valid_mse))\n",
        "    \n",
        "    def restore(self):\n",
        "        with open(\"./best_model/best_model.pt\", \"rb\") as f:\n",
        "            state_dict = torch.load(f)\n",
        "        self.load_state_dict(state_dict)\n",
        "\n",
        "    def predict(self, dataloader):\n",
        "        with torch.no_grad():\n",
        "            self.eval()\n",
        "            true_y = []\n",
        "            pred_y = []\n",
        "            for batch_x, batch_y in dataloader:\n",
        "                pred = self.forward(batch_x.to(self.device))\n",
        "                true_y.append(batch_y.numpy())\n",
        "                pred_y.append(pred.cpu().numpy())\n",
        "            true_y = np.concatenate(true_y, axis=0).squeeze()\n",
        "            pred_y = np.concatenate(pred_y, axis=0)\n",
        "        return true_y, pred_y #numpy array\n",
        "\n",
        "    def plot(self):\n",
        "        plt.plot(np.array(self.train_loss_val), \"b\")\n",
        "        plt.plot(np.array(self.train_acc_val), \"r\")\n",
        "        plt.plot(np.array(self.valid_acc_val), \"g\")\n",
        "        plt.savefig(\"graph.png\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "uNON_uCbmLkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0izhvsIDjxhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AIP"
      ],
      "metadata": {
        "id": "pvFu9VQSISVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data = train_test_split(pd.read_csv('./train.csv'), test_size = 0.1, random_state = 55)\n",
        "test_data = pd.read_csv('./test.csv')"
      ],
      "metadata": {
        "id": "360Pm1IVTtmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./data.pickle', 'rb') as f:\n",
        "    image_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "L1oulop1CTeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting hyper parameters\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "lr = 1e-5"
      ],
      "metadata": {
        "id": "RaVBtO6gmibN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = YoutubeDataset(train_data, image_data)\n",
        "valid_dataset = YoutubeDataset(valid_data, image_data)\n",
        "test_dataset = YoutubeDataset(test_data, image_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size = 1)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)"
      ],
      "metadata": {
        "id": "_d3vE8CgwOQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.train_(epochs, lr, train_loader, valid_loader, 10)"
      ],
      "metadata": {
        "id": "Vn1sTA9K-DBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot()"
      ],
      "metadata": {
        "id": "9--JTrRRKohy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}